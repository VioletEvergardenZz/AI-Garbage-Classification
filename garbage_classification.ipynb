{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "垃圾分类项目\n",
    "使用了深度学习中的卷积神经网络(CNN)来提取图像特征\n",
    "结合机器学习中的KNN和SVM算法进行分类和预测\n",
    "\n",
    "训练模型所使用设备：\n",
    "CPU: i5-11300H \n",
    "GPU: NVIDIA GeForce MX450   \n",
    "CUDA: 11.8\n",
    "\n",
    "代码编辑器: VSCode\n",
    "\n",
    "十次epoch大概用时20min\n",
    "程序得出测试集预测结果大概用时5h\n",
    "'''\n",
    "\n",
    "# 加载库\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),   \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  \n",
    "])\n",
    "\n",
    "# 自定义数据集类 --> 读取和整理训练集的图片和标签\n",
    "class GarbageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform   \n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # 遍历每个类别的目录，并将图像路径和标签添加到列表中\n",
    "        for label in range(40):\n",
    "            label_dir = os.path.join(self.root_dir, str(label))   # 找出每种垃圾的文件夹\n",
    "            if not os.path.isdir(label_dir):\n",
    "                print(f\"未找到目录: {label_dir}\")\n",
    "                continue\n",
    "            for img_name in os.listdir(label_dir):   # 遍历文件夹里的所有图片\n",
    "                img_path = os.path.join(label_dir, img_name)   # 图片的完整路径\n",
    "                if os.path.isfile(img_path):  \n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(label)\n",
    "        \n",
    "        print(f\"训练集图片总数: {len(self.image_paths)}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):   # 拿出一张特定的图片和它的标签\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label   # 返回处理后的图片和它的标签\n",
    "\n",
    "# 自定义测试数据集类  --> 读取测试数据，检查模型效果\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root_dir, file_path, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        with open(file_path, 'r') as f:\n",
    "            self.image_paths = [line.strip() for line in f]\n",
    "            print(f\"测试集图片总数: {len(self.image_paths)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.image_paths[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.image_paths[idx]    # 返回处理后的照片和它的路径\n",
    "\n",
    "# 加载训练数据\n",
    "print(\"加载训练数据...\")\n",
    "train_dataset = GarbageDataset(root_dir='train/train', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)   # 训练数据加载器 \n",
    "\n",
    "'卷积神经网络(CNN)模型定义和训练'\n",
    "# 定义模型\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # 卷积层\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        # 全连接层\n",
    "        self.fc1 = nn.Linear(128*16*16, 512)\n",
    "        self.fc2 = nn.Linear(512, 40)\n",
    "\n",
    "    # 前向传播过程\n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.conv1(x))    # 通过第一个卷积层，然后应用ReLU激活函数\n",
    "        x = nn.MaxPool2d(2, 2)(x)   # 应用2x2的最大池化层\n",
    "        x = nn.ReLU()(self.conv2(x))\n",
    "        x = nn.MaxPool2d(2, 2)(x)\n",
    "        x = nn.ReLU()(self.conv3(x))\n",
    "        x = nn.MaxPool2d(2, 2)(x)\n",
    "        x = x.view(-1, 128*16*16)   # 将特征展平为一维张量\n",
    "        x = nn.ReLU()(self.fc1(x))   # 通过第一个全连接层，然后应用ReLU激活函数\n",
    "        x = self.fc2(x)\n",
    "        return x   # 返回最终的输出\n",
    "\n",
    "     # 提取特征过程，不经过全连接层\n",
    "    def extract_features(self, x):\n",
    "        x = nn.ReLU()(self.conv1(x))\n",
    "        x = nn.MaxPool2d(2, 2)(x)\n",
    "        x = nn.ReLU()(self.conv2(x))\n",
    "        x = nn.MaxPool2d(2, 2)(x)\n",
    "        x = nn.ReLU()(self.conv3(x))\n",
    "        x = nn.MaxPool2d(2, 2)(x)\n",
    "        x = x.view(-1, 128*16*16)\n",
    "        return x   # 返回特征张量\n",
    "\n",
    "# 实例化模型、损失函数和优化器\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'当前使用的设备: {torch.cuda.get_device_name(0)}')\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # 交叉熵损失函数 \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)   # 优化器\n",
    "\n",
    "'模型训练'\n",
    "num_epochs = 10  # 将 epoch 数设置为 10\n",
    "print(\"开始训练...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 将CNN模型设置为训练模式\n",
    "    # 初始化运行中的损失、正确预测数量和总样本数\n",
    "    running_loss = 0.0  \n",
    "    correct = 0   \n",
    "    total = 0  \n",
    "    # 遍历训练数据加载器 对于每个batch（批次）中的inputs（输入图像）和labels（标签）\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)   # 使用定义的损失函数计算损失\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)   # 从输出中选择概率最高的类别\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    " \n",
    "    print(f'epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f},  Accuracy: {epoch_acc:.2f}%')\n",
    "\n",
    "# 保存模型\n",
    "print(\"保存模型...\")\n",
    "torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "'KNN和SVM分类器训练与预测'\n",
    "# 提取训练集特征\n",
    "print(\"提取训练数据特征...\")\n",
    "train_features = []\n",
    "train_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        features = model.extract_features(inputs).cpu().numpy()   # 提取输入图像的特征\n",
    "        train_features.append(features)\n",
    "        train_labels.append(labels.cpu().numpy())\n",
    "# 将train_features和train_labels列表中的所有数组连接起来,形成单个NumPy数组。\n",
    "train_features = np.concatenate(train_features)\n",
    "train_labels = np.concatenate(train_labels)\n",
    "\n",
    "# 定义 KNN 和 SVM 分类器\n",
    "print(\"训练 KNN 和 SVM 分类器...\")\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)   # 邻居数设置为5\n",
    "svm_classifier = SVC(kernel='linear')   # 使用线性核函数\n",
    "# 训练 KNN 和 SVM 分类器\n",
    "knn_classifier.fit(train_features, train_labels)\n",
    "svm_classifier.fit(train_features, train_labels)\n",
    "\n",
    "# 加载测试数据\n",
    "print(\"加载测试数据...\")\n",
    "test_dataset = TestDataset(root_dir='test/test', file_path='test/testpath.txt', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)   # 测试数据加载器\n",
    "\n",
    "# 加载训练好的模型\n",
    "print(\"加载训练好的模型...\")\n",
    "model.load_state_dict(torch.load('best_model.pth'))   # 从文件'best_model.pth'加载模型的预训练参数\n",
    "model.eval()   # 将模型设置为评估模式\n",
    "\n",
    "# 提取测试集特征并进行预测\n",
    "print(\"提取测试数据特征...\")\n",
    "test_features = []\n",
    "test_image_paths = []\n",
    "with torch.no_grad():\n",
    "    for inputs, image_paths in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        features = model.extract_features(inputs).cpu().numpy()\n",
    "        test_features.append(features)\n",
    "        test_image_paths.extend(image_paths)\n",
    "test_features = np.concatenate(test_features)\n",
    "\n",
    "# 使用 KNN 进行预测\n",
    "print(\"使用 KNN 进行预测...\")\n",
    "knn_predictions = knn_classifier.predict(test_features)\n",
    "\n",
    "# 使用 SVM 进行预测\n",
    "print(\"使用 SVM 进行预测...\")\n",
    "svm_predictions = svm_classifier.predict(test_features)\n",
    "\n",
    "# 保存预测结果\n",
    "print(\"保存预测结果...\")\n",
    "with open('knn.csv', 'w') as f:\n",
    "    for label in knn_predictions:\n",
    "        f.write(f'{label}\\n')\n",
    "\n",
    "with open('svm.csv', 'w') as f:\n",
    "    for label in svm_predictions:\n",
    "        f.write(f'{label}\\n')\n",
    "\n",
    "print(\"测试集图片分类完成。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
